from langchain.tools import tool
import chromadb
from chromadb.config import Settings as ChromaSettings
from config import settings
from models.pca_embeddings import pca_embeddings
from typing import Optional
import json
import logging
from utils.conversation_memory import get_shown_facility_names, set_status
from .naver_search_tool import naver_web_search

logger = logging.getLogger(__name__)

# ì„ê³„ê°’ (ì—„ê²©í•˜ê²Œ ì ìš©)
SIMILARITY_THRESHOLD = 1.1 

# ì£¼ì†Œ í•„í„°ë§ ì‹œ ë¬´ì‹œí•  ì¼ë°˜ ë‹¨ì–´ë“¤
IGNORE_LOCATION_TERMS = ["ì…êµ¬", "ì¶œêµ¬", "ê¸°êµ¬", "ì¹œêµ¬", "ì•¼êµ¬", "ì¶•êµ¬", "ë†êµ¬", "ë°°êµ¬", "ë„êµ¬", "ë¬¸êµ¬", "ì•„ë™", "ìš´ë™", "í™œë™", "í–‰ë™"]

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    chroma_client = chromadb.HttpClient(
        host=settings.CHROMA_HOST,
        port=settings.CHROMA_PORT,
        settings=ChromaSettings(anonymized_telemetry=False)
    )
    collection = chroma_client.get_collection(name="kid_program_collection")
except Exception as e:
    logger.error(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
    collection = None

@tool
async def search_facilities(
    original_query: str,
    conversation_id: str,
    location: str = "",
    indoor_outdoor: str = "",
    k: int = 3 
) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‹œì„¤ì„ RAG(DB)ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì§€ì—­ëª…(ì‹œ/êµ°/êµ¬/ë™)ê³¼ ì‹¤ë‚´ì™¸ ì—¬ë¶€ë¥¼ ì •ë°€í•˜ê²Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” RAG ê²€ìƒ‰ | Q: {original_query} | Loc: {location} | InOut: {indoor_outdoor}")
    
    if conversation_id:
        set_status(conversation_id, "ì‹œì„¤ í›„ë³´ ì°¾ëŠ” ì¤‘..")

    if collection is None:
        return json.dumps({"success": False, "facilities": []})
    
    try:
        # ì„ë² ë”© ìƒì„± (ë™ê¸° ì‘ì—…ì´ì§€ë§Œ ë¹ ë¥´ë¯€ë¡œ ìœ ì§€)
        query_embedding = pca_embeddings.embed_query(original_query)
        shown_facilities = get_shown_facility_names(conversation_id) if conversation_id else []

        # ì¿¼ë¦¬ ì‹¤í–‰
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=10, 
            include=["metadatas", "documents", "distances"]
        )
        
        facilities = []
        
        if results and results['ids'] and len(results['ids'][0]) > 0:
            metadatas = results['metadatas'][0]
            documents = results['documents'][0]
            distances = results['distances'][0]
            
            # ìƒì„¸ ì£¼ì†Œ í•„í„°ë§ìš© ë‹¨ì–´ ì¶”ì¶œ
            query_words = original_query.split()
            detail_locations = []
            for w in query_words:
                if len(w) >= 2 and w[-1] in ["ì‹œ", "êµ°", "êµ¬", "ë™", "ì", "ë©´"]:
                    if w not in IGNORE_LOCATION_TERMS:
                        detail_locations.append(w)
            
            if detail_locations:
                logger.info(f"ğŸ“ ìƒì„¸ ì§€ì—­ í•„í„° ê°ì§€: {detail_locations}")

            for i, metadata in enumerate(metadatas):
                name = metadata.get("Name", metadata.get("name", "ì´ë¦„ì—†ìŒ"))
                address = metadata.get("Address", "")
                db_in_out = metadata.get("in_out", "") 
                current_dist = distances[i]

                # [í•„í„°ë§ 1] ì¤‘ë³µ ì œì™¸
                if name in shown_facilities:
                    continue

                # [í•„í„°ë§ 2] ìœ ì‚¬ë„ ê±°ë¦¬
                if current_dist > SIMILARITY_THRESHOLD:
                    logger.warning(f"  âŒ [íƒˆë½:ê±°ë¦¬] {name} ({current_dist:.2f})")
                    continue 

                # [í•„í„°ë§ 3] ê¸°ë³¸ ì§€ì—­ í•„í„°
                if location and location not in address:
                    logger.warning(f"  âŒ [íƒˆë½:ì§€ì—­ê¸°ë³¸] {name} (ì£¼ì†Œ:{address} vs ìš”ì²­:{location})")
                    continue

                # [í•„í„°ë§ 4] ìƒì„¸ ì£¼ì†Œ í•„í„°
                is_detail_match = True
                for detail_loc in detail_locations:
                    if detail_loc not in address:
                        logger.warning(f"  âŒ [íƒˆë½:ì„¸ë¶€ì§€ì—­] {name} (ì£¼ì†Œì— '{detail_loc}' ì—†ìŒ)")
                        is_detail_match = False
                        break
                if not is_detail_match:
                    continue

                # [í•„í„°ë§ 5] ì‹¤ë‚´/ì‹¤ì™¸
                if indoor_outdoor:
                    if indoor_outdoor not in db_in_out:
                         logger.warning(f"  âŒ [íƒˆë½:ì‹¤ë‚´ì™¸] {name} (DB:{db_in_out} != Req:{indoor_outdoor})")
                         continue

                # í†µê³¼
                category = metadata.get("Category3") or metadata.get("Category1")
                desc = documents[i][:100] if i < len(documents) else address[:100]
                
                facilities.append({
                    "name": name,
                    "lat": float(metadata.get("LAT", 0.0)),
                    "lng": float(metadata.get("LON", 0.0)),
                    "category": category,
                    "desc": desc,
                    "in_out": db_in_out,
                    "distance": current_dist
                })

        facilities = facilities[:k]
        
        # [Fallback] RAG ê²€ìƒ‰ ê²°ê³¼ 0ê±´ ì‹œ, naver_web_search í´ë°± ì‹¤í–‰
        if not facilities:
            logger.warning("ğŸš« RAG ê²€ìƒ‰ ê²°ê³¼ 0ê±´. naver_web_searchë¡œ í´ë°± ì‹¤í–‰.")
            set_status(conversation_id, "RAG ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ í´ë°± ì‹¤í–‰ ì¤‘...")
            
            web_search_output = await naver_web_search.ainvoke({
                "query": original_query, 
                "conversation_id": conversation_id
            })
            return web_search_output 

        logger.info(f"âœ… ìµœì¢… RAG ê²°ê³¼: {len(facilities)}ê°œ ë°˜í™˜")
        
        return json.dumps({
            "success": True,
            "count": len(facilities),
            "facilities": facilities
        }, ensure_ascii=False)
        
    except Exception as e:
        logger.error(f"âŒ RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return json.dumps({"success": False, "facilities": []})
