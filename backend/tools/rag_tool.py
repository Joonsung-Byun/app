from langchain.tools import tool
import chromadb
from chromadb.config import Settings as ChromaSettings
from config import settings
from models.pca_embeddings import pca_embeddings
from typing import Optional
import json
import logging
from utils.conversation_memory import get_shown_facility_names, set_status
from utils.location_mapper import CITY_TO_PROVINCE_SIGNGU
from .naver_search_tool import naver_web_search

logger = logging.getLogger(__name__)

def _safe_float(value, default=0.0) -> float:
    """ìˆ«ì ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’ ë°˜í™˜"""
    try:
        return float(value)
    except (TypeError, ValueError):
        return default

# ì„ê³„ê°’ (ì—„ê²©í•˜ê²Œ ì ìš©)
SIMILARITY_THRESHOLD = 1.1 

# ì£¼ì†Œ í•„í„°ë§ ì‹œ ë¬´ì‹œí•  ì¼ë°˜ ë‹¨ì–´ë“¤
IGNORE_LOCATION_TERMS = ["ì…êµ¬", "ì¶œêµ¬", "ê¸°êµ¬", "ì¹œêµ¬", "ì•¼êµ¬", "ì¶•êµ¬", "ë†êµ¬", "ë°°êµ¬", "ë„êµ¬", "ë¬¸êµ¬", "ì•„ë™", "ìš´ë™", "í™œë™", "í–‰ë™"]

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    chroma_client = chromadb.HttpClient(
        host=settings.CHROMA_HOST,
        port=settings.CHROMA_PORT,
        settings=ChromaSettings(anonymized_telemetry=False)
    )
    collection = chroma_client.get_collection(name="kid_program_collection")
except Exception as e:
    logger.error(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
    collection = None

@tool
async def search_facilities(
    original_query: str,
    conversation_id: str,
    location: str = "",
    indoor_outdoor: str = "",
    k: int = 3 
) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‹œì„¤ì„ RAG(DB)ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì§€ì—­ëª…(ì‹œ/êµ°/êµ¬/ë™)ê³¼ ì‹¤ë‚´ì™¸ ì—¬ë¶€ë¥¼ ì •ë°€í•˜ê²Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ” RAG ê²€ìƒ‰ | Q: {original_query} | Loc: {location} | InOut: {indoor_outdoor}")
    
    if conversation_id:
        set_status(conversation_id, "ì‹œì„¤ í›„ë³´ ì°¾ëŠ” ì¤‘..")

    if collection is None:
        return json.dumps({"success": False, "facilities": []})
    
    try:
        # ì„ë² ë”© ìƒì„± (ë¹„ë™ê¸° ì „í™˜)
        query_embedding = await pca_embeddings.aembed_query(original_query)
        shown_facilities = get_shown_facility_names(conversation_id) if conversation_id else []

        # -------------------------------------------------------------------
        # Pre-filtering: location ë§¤í•‘ ì •ë³´ë¥¼ í™œìš©í•´ Chroma where ì ˆ ì ìš©
        # -------------------------------------------------------------------
        where_clause = None
        if location:
            loc_info = CITY_TO_PROVINCE_SIGNGU.get(location)
            if loc_info:
                ctprvn_nm = loc_info[0]
                if len(loc_info) > 1:
                    signgu_nm = loc_info[1]
                    where_clause = {
                        "$and": [
                            {"CTPRN_NM": {"$eq": ctprvn_nm}},
                            {"SIGNGU_NM": {"$eq": signgu_nm}}
                        ]
                    }
                    logger.info(f"âš¡ ì§€ì—­ ì •ë°€ í•„í„°(ì‹œë„+ì‹œêµ°êµ¬): {ctprvn_nm} {signgu_nm}")
                else:
                    where_clause = {"CTPRN_NM": {"$eq": ctprvn_nm}}
                    logger.info(f"âš¡ ì§€ì—­ ê´‘ì—­ í•„í„°(ì‹œë„): {ctprvn_nm}")
            else:
                logger.warning(f"âš ï¸ ë§¤í•‘ë˜ì§€ ì•Šì€ ì§€ì—­ëª…: {location} (ì‚¬ì „ í•„í„° ë¯¸ì ìš©)")

        # ì¿¼ë¦¬ ì‹¤í–‰ (ì‚¬ì „ í•„í„° where_clause ì ìš©)
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=50,
            where=where_clause,
            include=["metadatas", "documents", "distances"]
        )

        # ì§€ì—­ where í•„í„°ë¡œ 0ê±´ì´ë©´ í•„í„° ì œê±° í›„ ì¬ì‹œë„
        if (
            (not results)
            or (not results.get("ids"))
            or (not results["ids"][0])
        ) and where_clause:
            logger.warning("âš ï¸ ì§€ì—­ where í•„í„° ê²°ê³¼ 0ê±´ -> í•„í„° ì—†ì´ ì¬ì‹œë„")
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=50,
                include=["metadatas", "documents", "distances"]
            )
        
        facilities = []
        
        if results and results['ids'] and len(results['ids'][0]) > 0:
            metadatas = results['metadatas'][0]
            documents = results['documents'][0]
            distances = results['distances'][0]
            
            # ìƒì„¸ ì£¼ì†Œ í•„í„°ë§ìš© ë‹¨ì–´ ì¶”ì¶œ
            query_words = original_query.split()
            detail_locations = []
            for w in query_words:
                if len(w) >= 2 and w[-1] in ["ì‹œ", "êµ°", "êµ¬", "ë™", "ì", "ë©´"]:
                    if w not in IGNORE_LOCATION_TERMS:
                        detail_locations.append(w)
            
            if detail_locations:
                logger.info(f"ğŸ“ ìƒì„¸ ì§€ì—­ í•„í„° ê°ì§€: {detail_locations}")

            for i, metadata in enumerate(metadatas):
                name = metadata.get("Name", metadata.get("name", "ì´ë¦„ì—†ìŒ"))
                address = metadata.get("Address", "")
                db_in_out = metadata.get("in_out", "") 
                current_dist = distances[i]

                # [í•„í„°ë§ 1] ì¤‘ë³µ ì œì™¸
                if name in shown_facilities:
                    continue

                # [í•„í„°ë§ 2] ìœ ì‚¬ë„ ê±°ë¦¬
                if current_dist > SIMILARITY_THRESHOLD:
                    logger.warning(f"  âŒ [íƒˆë½:ê±°ë¦¬] {name} ({current_dist:.2f})")
                    continue 

                # [í•„í„°ë§ 3] ê¸°ë³¸ ì§€ì—­ í•„í„°
                if location and location not in address:
                    logger.warning(f"  âŒ [íƒˆë½:ì§€ì—­ê¸°ë³¸] {name} (ì£¼ì†Œ:{address} vs ìš”ì²­:{location})")
                    continue

                # [í•„í„°ë§ 4] ìƒì„¸ ì£¼ì†Œ í•„í„°
                is_detail_match = True
                for detail_loc in detail_locations:
                    if detail_loc not in address:
                        logger.warning(f"  âŒ [íƒˆë½:ì„¸ë¶€ì§€ì—­] {name} (ì£¼ì†Œì— '{detail_loc}' ì—†ìŒ)")
                        is_detail_match = False
                        break
                if not is_detail_match:
                    continue

                # [í•„í„°ë§ 5] ì‹¤ë‚´/ì‹¤ì™¸
                if indoor_outdoor:
                    if indoor_outdoor not in db_in_out:
                         logger.warning(f"  âŒ [íƒˆë½:ì‹¤ë‚´ì™¸] {name} (DB:{db_in_out} != Req:{indoor_outdoor})")
                         continue

                # í†µê³¼
                category = metadata.get("Category3") or metadata.get("Category1")
                desc = documents[i][:100] if i < len(documents) else address[:100]
                lat_val = _safe_float(metadata.get("LAT", 0.0))
                lng_val = _safe_float(metadata.get("LON", 0.0))

                facilities.append({
                    "name": name,
                    "lat": lat_val,
                    "lng": lng_val,
                    "category": category,
                    "desc": desc,
                    "in_out": db_in_out
                })

        facilities = facilities[:k]
        
        # [Fallback] RAG ê²€ìƒ‰ ê²°ê³¼ 0ê±´ ì‹œ, naver_web_search í´ë°± ì‹¤í–‰
        if not facilities:
            logger.warning("ğŸš« RAG ê²€ìƒ‰ ê²°ê³¼ 0ê±´. naver_web_searchë¡œ í´ë°± ì‹¤í–‰.")
            set_status(conversation_id, "RAG ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ í´ë°± ì‹¤í–‰ ì¤‘...")
            
            fallback_query = original_query if not location else f"{original_query} {location}"
            web_search_output = await naver_web_search.ainvoke({
                "query": fallback_query,
                "conversation_id": conversation_id
            })
            return web_search_output 

        logger.info(f"âœ… ìµœì¢… RAG ê²°ê³¼: {len(facilities)}ê°œ ë°˜í™˜")
        
        return json.dumps({
            "success": True,
            "count": len(facilities),
            "facilities": facilities
        }, ensure_ascii=False)
        
    except Exception as e:
        logger.error(f"âŒ RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return json.dumps({"success": False, "facilities": []})
