# 성능 평가 리포트 (개선판)

**평가 일시**: 2025-11-25T20:15:25.549635

**평가 질문 수**: 211

---

## 1. 답변 품질 (LLM-as-Judge)

> GPT-4o-mini를 Judge로 사용하여 각 답변의 품질을 1-5점 척도로 평가

| 항목 | 평균 | 표준편차 | 최소 | 최대 | 해석 |
|------|------|----------|------|------|------|
| 정확성 | 3.48 | 1.55 | 1 | 5 | ⚠️ 가장 낮은 점수, 개선 필요 |
| 관련성 | 4.00 | 1.42 | 1 | 5 | ✅ 질문과 답변이 적절히 연결됨 |
| 유용성 | 3.96 | 1.28 | 1 | 5 | ✅ 어린이에게 유용한 답변 |
| **종합** | **3.75** | 1.43 | 1 | 5 | **75% 수준의 품질** |

### 평가 기준
- **정확성**: 답변이 사실적으로 정확한가?
- **관련성**: 질문에 적절하게 답했는가?
- **유용성**: 어린이에게 도움이 되는 답변인가?


## 2. Tool 사용 정확도

> AI가 적절한 Tool을 선택하고, 올바른 파라미터로 호출했는지 평가

### 전체 정확도

| 지표 | 정확도 | 설명 |
|------|--------|------|
| **Tool 선택 정확도** | 67.6% | 올바른 Tool을 선택한 비율 |
| **파라미터 정확도** | 70.6% | Tool에 전달한 입력값이 정확한 비율 |
| **종합 정확도** | 47.4% | Tool 선택과 파라미터가 모두 정확한 비율 |

⚠️ **종합 정확도가 낮은 이유**: Tool을 올바르게 선택하고(67.6%), 파라미터도 정확해야(70.6%) 하므로 0.676 × 0.706 ≈ 0.47


### 파라미터 정확도란?

Tool을 올바르게 선택해도, **입력값이 잘못되면** 원하는 결과를 얻을 수 없습니다.

**예시 1: 시설 검색**
```
질문: "강남구에서 미술관 찾아줘"

✅ 정확한 호출 (파라미터 정확도: 100%)
Tool: search_facilities
입력: { region: "강남구", category: "미술관" }

⚠️ 부분 정확 (파라미터 정확도: 50%)
Tool: search_facilities
입력: { region: "강남구", category: "박물관" } ← 카테고리 틀림

❌ 틀린 호출 (파라미터 정확도: 0%)
Tool: search_facilities
입력: { region: "서초구", category: "카페" } ← 둘 다 틀림
```

**예시 2: 날씨 조회**
```
질문: "내일 부산 날씨 알려줘"

✅ 정확한 호출
Tool: get_weather_forecast
입력: { location: "부산", date: "2025-11-26" }

❌ 틀린 호출
Tool: get_weather_forecast
입력: { location: "서울", date: "2025-11-26" } ← 위치 틀림
```


### 카테고리별 정확도

| 카테고리 | 질문 수 | Tool 선택 | 파라미터 |
|----------|---------|-----------|----------|
| unknown | 20 | 93.3% | 0.0% |


### 툴별 호출 성공률

| 툴 | 기대 호출 | 실제 호출(히트) | 성공률 | 평가 |
|----|----------|---------------|--------|------|
| search_map_by_address | 20 | 20 | 100.0% | ✅ 완벽 |
| naver_web_search | 44 | 42 | 95.5% | ✅ 매우 우수 |
| search_facilities | 130 | 108 | 83.1% | ✅ 우수 |
| get_weather_forecast | 75 | 52 | 69.3% | ⚠️ 개선 필요 |


## 3. 서비스 품질 (케이스별)

> 실제 서비스 시나리오별로 AI가 올바른 Tool을 호출했는지 평가

| 케이스 | 성공률 | 샘플 수 | 지표 설명 | 평가 |
|--------|--------|---------|-----------|------|
| weather | 100.0% | 25 | 날씨 조회 호출 | ✅ 완벽 |
| case2 | 100.0% | 40 | 시설 검색 호출 | ✅ 완벽 |
| map | 100.0% | 20 | 지도 관련 도구 호출 | ✅ 완벽 |
| case2_review | 95.0% | 20 | 시설 검색 호출 (리뷰) | ✅ 매우 우수 |
| web | 91.7% | 24 | 웹 검색 호출 | ✅ 매우 우수 |
| weather_places | 50.0% | 50 | 날씨 확인 후 시설 검색 호출 | ⚠️ 복합 케이스 개선 필요 |
| no_tool | 8.3% | 12 | 도구를 사용하지 않아야 함 | ❌ 심각한 문제 |
| case3_fallback | 5.0% | 20 | RAG 0건 → web_search까지 호출 | ❌ Fallback 로직 개선 필요 |

### 케이스별 분석

**✅ 우수한 영역 (90%+)**
- 단일 Tool 호출 케이스는 매우 안정적
- weather, case2, map, web 모두 우수

**⚠️ 개선 필요 영역**
- **weather_places (50%)**: 날씨 + 시설 검색을 순차적으로 호출하는 복합 케이스
  - 두 Tool을 모두 호출해야 하는데, 하나만 호출하거나 순서가 잘못됨

**❌ 심각한 문제**
- **no_tool (8.3%)**: Tool을 사용하지 말아야 할 때 91.7%가 잘못 호출
  - AI가 "대답만 하면 되는 질문"에도 불필요하게 Tool을 호출

- **case3_fallback (5%)**: RAG 검색 결과가 없을 때 웹 검색으로 전환해야 하는데 95%가 실패
  - Fallback 메커니즘이 제대로 작동하지 않음


## 4. RAG 검색 품질

> ChromaDB + PCA 임베딩을 사용한 벡터 검색 성능 평가

### 핵심 지표

| 지표 | 값 | 설명 | 평가 |
|------|-----|------|------|
| **Precision@3** | 0.599 | 상위 3개 결과 중 정답 비율 (59.9%) | ⚠️ 보통 |
| **Recall@20** | 0.559 | 상위 20개에 전체 정답의 55.9% 포함 | ⚠️ 보통 |
| **F1-Score** | 0.578 | Precision과 Recall의 조화평균 (57.8%) | ⚠️ 보통 |

### 지표 설명

- **Precision@3**: 상위 3개 검색 결과 중 몇 개가 정답인가?
  - 현재: 3개 중 평균 1.8개가 정답 (59.9%)
  - 목표: 80% 이상 (3개 중 2.4개)

- **Recall@20**: 전체 정답 문서를 상위 20개에서 얼마나 찾아냈는가?
  - 현재: 전체 정답의 55.9%만 상위 20개에 포함
  - 목표: 80% 이상

- **F1-Score**: Precision과 Recall의 균형을 나타내는 조화평균
  - 계산식: `2 × (Precision × Recall) / (Precision + Recall)`
  - 현재: 0.578 (57.8%)
  - 목표: 0.80 이상

### 개선 방안
1. **임베딩 모델 개선**: 더 강력한 한국어 임베딩 모델 적용
2. **하이브리드 검색**: 벡터 검색 + 키워드 검색 조합
3. **리랭킹**: Cross-encoder로 재정렬
4. **청킹 전략**: 문서 분할 방식 최적화


## 5. 시스템 성능

### 응답 시간

| 지표 | 시간 | 평가 |
|------|------|------|
| 평균 | **14.69s** (±12.52s) | ⚠️ 개선 필요 |
| P50 (중앙값) | 10.32s | ⚠️ 10초 이상 |
| P90 | 33.95s | ❌ 매우 느림 |
| P99 | 44.53s | ❌ 매우 느림 |

⚠️ **표준편차가 큼(±12.52s)**: 케이스별로 응답 시간 편차가 매우 크다는 의미


### 메모리 사용량

| 항목 | 용량 | 평가 |
|------|------|------|
| 초기 메모리 | 433.9 MB | - |
| 최종 메모리 | 420.1 MB | ✅ 메모리 누수 없음 |
| 피크 메모리 | 513.8 MB | ✅ 안정적 |

✅ **메모리 관리 우수**: 오히려 감소(-13.8 MB), 가비지 컬렉션 정상 작동


### 성공률

**100.0% (211/211)** ✅

모든 질문에 대해 예외 없이 응답 생성 (완벽한 안정성)


### 가중 평균 응답 시간

**13.12s** (케이스 중요도 가중치 적용)


### 케이스별 응답 시간

| 케이스 | 샘플 수 | 평균(s) | P90(s) | 평가 |
|--------|---------|---------|--------|------|
| map | 20 | 1.35 | 1.65 | ✅ 매우 빠름 |
| no_tool | 12 | 2.24 | 2.86 | ✅ 매우 빠름 |
| weather | 25 | 5.06 | 7.26 | ✅ 빠름 |
| web | 24 | 12.49 | 28.59 | ⚠️ 느림 |
| case2 | 40 | 15.13 | 29.56 | ⚠️ 느림 |
| case2_review | 20 | 18.49 | 34.76 | ⚠️ 느림 |
| weather_places | 50 | 20.14 | 37.88 | ❌ 매우 느림 |
| case3_fallback | 20 | 31.89 | 37.02 | ❌ 매우 느림 |

### 응답 시간 분석

**✅ 빠른 케이스 (< 10초)**
- **map (1.35s)**: 지도 검색은 단순 API 호출만 필요
- **no_tool (2.24s)**: Tool 호출 없이 바로 응답
- **weather (5.06s)**: 날씨 API 단일 호출

**⚠️ 느린 케이스 (10-20초)**
- **web (12.49s)**: 웹 검색 API 대기 시간
- **case2 (15.13s)**: RAG 검색 + 임베딩 계산
- **case2_review (18.49s)**: RAG 검색 + 리뷰 분석

**❌ 매우 느린 케이스 (> 20초)**
- **weather_places (20.14s)**: 날씨 + 시설 검색 (순차 호출)
- **case3_fallback (31.89s)**: RAG 실패 → 웹 검색 전환 (이중 시도)


---

## 종합 평가 및 개선 로드맵

### 📊 현재 상태 요약

| 영역 | 점수/성능 | 등급 |
|------|-----------|------|
| 답변 품질 (종합) | 3.75 / 5.0 | 🟡 보통 |
| Tool 종합 정확도 | 47.4% | 🔴 낮음 |
| 단일 케이스 성공률 | 95-100% | 🟢 우수 |
| 복합 케이스 성공률 | 5-50% | 🔴 매우 낮음 |
| RAG F1-Score | 0.578 | 🟡 보통 |
| 평균 응답 시간 | 14.69s | 🟡 보통 |
| 시스템 안정성 | 100% | 🟢 완벽 |


### 🎯 우선순위별 개선 과제

#### **Priority 1 (긴급) - 기능 정확성**

1. **no_tool 판단 로직 개선** ❌ 8.3% → 🎯 90%+
   - 현상: Tool이 필요 없는데도 91.7%가 잘못 호출
   - 원인: AI가 Tool 호출 여부를 판단하는 로직 부재
   - 해결:
     - 프롬프트에 "도구가 필요한 경우만 사용" 명시
     - 질문 유형 분류기 추가 (일반 대화 vs 기능 요청)

2. **case3_fallback 메커니즘 재설계** ❌ 5.0% → 🎯 80%+
   - 현상: RAG 결과 없을 때 웹 검색으로 전환 실패
   - 원인: Fallback 트리거 조건이 명확하지 않음
   - 해결:
     - RAG 결과 신뢰도 점수 도입
     - 임계값 이하 시 자동으로 웹 검색 호출


#### **Priority 2 (중요) - 복합 케이스 성능**

3. **weather_places 순차 호출 개선** ⚠️ 50.0% → 🎯 85%+
   - 현상: 날씨와 시설 검색을 모두 호출해야 하는데 하나만 호출
   - 원인: 복합 의도 파악 부족, Tool 체이닝 로직 미흡
   - 해결:
     - 다단계 Task 계획 수립 (Plan → Execute)
     - "날씨 확인 → 결과 기반으로 장소 추천" 템플릿 추가

4. **파라미터 정확도 향상** ⚠️ 70.6% → 🎯 90%+
   - 해결:
     - Few-shot 예시 강화 (파라미터 형식 명확히)
     - 구조화된 출력 (JSON schema) 강제
     - 파라미터 검증 레이어 추가


#### **Priority 3 (개선) - 검색 품질**

5. **RAG 검색 정확도 개선** ⚠️ F1: 0.578 → 🎯 0.80+
   - 해결:
     - 하이브리드 검색 도입 (벡터 + BM25)
     - 임베딩 모델 업그레이드 (multilingual-e5 → OpenAI ada-002)
     - 쿼리 확장 (Query expansion)
     - 리랭킹 모델 추가

6. **답변 정확성 향상** 🟡 3.48 → 🎯 4.2+
   - 해결:
     - 검색 품질 개선 (위 5번과 연계)
     - 사실 검증 레이어 추가
     - 환각 방지 프롬프트 강화
     - Ground truth 명시적 참조


#### **Priority 4 (최적화) - 성능 개선**

7. **응답 속도 최적화** ⚠️ 14.69s → 🎯 <10s
   - 해결:
     - RAG 검색 결과 캐싱 (동일/유사 질문)
     - 병렬 Tool 호출 (독립적인 Tool은 동시 실행)
     - 임베딩 배치 처리
     - 프롬프트 토큰 수 최적화

8. **case3_fallback 응답 시간 단축** ❌ 31.89s → 🎯 <20s
   - 해결:
     - 조기 종료 조건 설정 (RAG 신뢰도 임계값)
     - 타임아웃 설정 (무한 대기 방지)


### 📈 기대 효과 (개선 완료 시)

| 지표 | 현재 | 목표 | 개선률 |
|------|------|------|--------|
| Tool 종합 정확도 | 47.4% | 80%+ | +69% |
| 복합 케이스 성공률 | 5-50% | 80%+ | +400-1500% |
| RAG F1-Score | 0.578 | 0.80+ | +38% |
| 평균 응답 시간 | 14.69s | <10s | -32% |
| 답변 정확성 | 3.48 | 4.2+ | +21% |


### 🔍 모니터링 지표

개선 후 지속적으로 추적해야 할 KPI:
- Tool 종합 정확도 > 80%
- no_tool 판단 정확도 > 90%
- 평균 응답 시간 < 10초
- RAG F1-Score > 0.80
- 사용자 만족도 (답변 품질) > 4.0/5.0


---

**보고서 생성 일시**: 2025-11-25
**개선판 버전**: v2.0 (F1-Score 추가, MRR 제거)
