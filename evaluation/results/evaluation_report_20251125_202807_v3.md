# 성능 평가 리포트

**평가 일시**: 2025-11-25T20:15:25.549635

**평가 질문 수**: 211

---

## 1. 답변 품질 (LLM-as-Judge)

> GPT-4o-mini를 Judge로 사용하여 각 답변의 품질을 1-5점 척도로 평가

| 항목 | 평균 | 표준편차 | 최소 | 최대 | 해석 |
|------|------|----------|------|------|------|
| 정확성 | 3.48 | 1.55 | 1 | 5 | ⚠️ 가장 낮은 점수, 개선 필요 |
| 관련성 | 4.00 | 1.42 | 1 | 5 | ✅ 질문과 답변이 적절히 연결됨 |
| 유용성 | 3.96 | 1.28 | 1 | 5 | ✅ 어린이에게 유용한 답변 |
| **종합** | **3.75** | 1.43 | 1 | 5 | **75% 수준의 품질** |

### 평가 기준
- **정확성**: 답변이 사실적으로 정확한가?
- **관련성**: 질문에 적절하게 답했는가?
- **유용성**: 어린이에게 도움이 되는 답변인가?


## 2. Tool 선택 정확도

> AI가 질문에 적합한 Tool을 선택했는지 평가

### 전체 정확도

**Tool 선택 정확도: 67.6%**

AI가 올바른 Tool을 선택한 비율입니다. Jaccard 유사도를 사용하여 계산:
- 기대되는 Tool들과 실제 호출된 Tool들의 교집합 / 합집합
- 예: 기대 {날씨, 시설검색}, 실제 {날씨, 시설검색} → 100%
- 예: 기대 {날씨, 시설검색}, 실제 {날씨} → 66.7%


### 툴별 호출 성공률

| 툴 | 기대 호출 | 실제 호출 | 성공률 | 평가 |
|----|----------|----------|--------|------|
| search_map_by_address | 20 | 20 | 100.0% | ✅ 완벽 |
| naver_web_search | 44 | 42 | 95.5% | ✅ 매우 우수 |
| search_facilities | 130 | 108 | 83.1% | ✅ 우수 |
| get_weather_forecast | 75 | 52 | 69.3% | ⚠️ 개선 필요 |

**총 269회 기대 호출 중 222회 성공 (82.5%)**


## 3. 서비스 품질 (케이스별)

> 실제 서비스 시나리오별로 AI가 올바른 Tool을 호출했는지 평가

| 케이스 | 성공률 | 샘플 수 | 시나리오 설명 | 평가 |
|--------|--------|---------|--------------|------|
| weather | 100.0% | 25 | 날씨 조회 호출 | ✅ 완벽 |
| case2 | 100.0% | 40 | 시설 검색 호출 | ✅ 완벽 |
| map | 100.0% | 20 | 지도 관련 도구 호출 | ✅ 완벽 |
| case2_review | 95.0% | 20 | 시설 검색 호출 (리뷰) | ✅ 매우 우수 |
| web | 91.7% | 24 | 웹 검색 호출 | ✅ 매우 우수 |
| weather_places | 50.0% | 50 | 날씨 + 시설 검색 (복합) | ⚠️ 개선 필요 |
| no_tool | 8.3% | 12 | Tool 사용하지 않아야 함 | ❌ 심각한 문제 |
| case3_fallback | 5.0% | 20 | RAG 0건 → 웹 검색 전환 | ❌ 심각한 문제 |

### 케이스별 분석

#### ✅ 우수한 영역 (90%+) - 단일 Tool 호출
- **weather (100%)**: "내일 서울 날씨 어때?" → get_weather_forecast 호출
- **case2 (100%)**: "강남구 미술관 찾아줘" → search_facilities 호출
- **map (100%)**: "서울역 지도에서 보여줘" → search_map_by_address 호출
- **web (91.7%)**: "부산 불꽃축제 언제야?" → naver_web_search 호출

**특징**: 단일 Tool만 필요한 케이스는 매우 안정적

#### ⚠️ 개선 필요 영역 - 복합 Tool 호출
- **weather_places (50%)**
  - 시나리오: "내일 날씨 좋으면 놀이터 추천해줘"
  - 기대: get_weather_forecast → search_facilities (순차 호출)
  - 문제: 날씨만 확인하거나, 시설만 검색하는 경우가 많음
  - 원인: 복합 의도 파악 부족, Tool 체이닝 로직 미흡

#### ❌ 심각한 문제
- **no_tool (8.3%)**
  - 시나리오: "안녕?" "고마워" 같은 일반 대화
  - 기대: Tool 호출 없이 바로 답변
  - 문제: 91.7%가 불필요하게 Tool을 호출
  - 원인: Tool 필요 여부 판단 로직 부재

- **case3_fallback (5%)**
  - 시나리오: RAG 검색 결과가 없을 때 웹 검색으로 전환
  - 기대: search_facilities → (결과 없음) → naver_web_search
  - 문제: 95%가 Fallback 전환 실패
  - 원인: Fallback 트리거 조건 불명확


## 4. RAG 검색 품질

> ChromaDB + PCA 임베딩을 사용한 벡터 검색 성능 평가

### 핵심 지표

| 지표 | 값 | 설명 | 평가 |
|------|-----|------|------|
| **Precision@3** | 0.599 | 상위 3개 결과 중 정답 비율 (59.9%) | ⚠️ 보통 |
| **Recall@20** | 0.559 | 상위 20개에 전체 정답의 55.9% 포함 | ⚠️ 보통 |
| **F1-Score** | 0.578 | Precision과 Recall의 조화평균 (57.8%) | ⚠️ 보통 |

### 지표 설명

- **Precision@3**: 상위 3개 검색 결과 중 몇 개가 정답인가?
  - 현재: 3개 중 평균 1.8개가 정답 (59.9%)
  - 목표: 80% 이상 (3개 중 2.4개)

- **Recall@20**: 전체 정답 문서를 상위 20개에서 얼마나 찾아냈는가?
  - 현재: 전체 정답의 55.9%만 상위 20개에 포함
  - 목표: 80% 이상

- **F1-Score**: Precision과 Recall의 균형을 나타내는 조화평균
  - 계산식: `2 × (Precision × Recall) / (Precision + Recall)`
  - 현재: 0.578 (57.8%)
  - 목표: 0.80 이상

### 개선 방안
1. **임베딩 모델 개선**: 더 강력한 한국어 임베딩 모델 적용
2. **하이브리드 검색**: 벡터 검색 + 키워드 검색(BM25) 조합
3. **리랭킹**: Cross-encoder로 재정렬
4. **청킹 전략**: 문서 분할 방식 최적화


## 5. 시스템 성능

### 응답 시간

| 지표 | 시간 | 평가 |
|------|------|------|
| 평균 | **14.69s** (±12.52s) | ⚠️ 개선 필요 |
| P50 (중앙값) | 10.32s | ⚠️ 10초 이상 |
| P90 | 33.95s | ❌ 매우 느림 |
| P99 | 44.53s | ❌ 매우 느림 |

⚠️ **표준편차가 큼(±12.52s)**: 케이스별로 응답 시간 편차가 매우 크다는 의미


### 메모리 사용량

| 항목 | 용량 | 평가 |
|------|------|------|
| 초기 메모리 | 433.9 MB | - |
| 최종 메모리 | 420.1 MB | ✅ 메모리 누수 없음 |
| 피크 메모리 | 513.8 MB | ✅ 안정적 |

✅ **메모리 관리 우수**: 오히려 감소(-13.8 MB), 가비지 컬렉션 정상 작동


### 성공률

**100.0% (211/211)** ✅

모든 질문에 대해 예외 없이 응답 생성 (완벽한 안정성)


### 가중 평균 응답 시간

**13.12s** (케이스 중요도 가중치 적용)


### 케이스별 응답 시간

| 케이스 | 샘플 수 | 평균(s) | P90(s) | 평가 |
|--------|---------|---------|--------|------|
| map | 20 | 1.35 | 1.65 | ✅ 매우 빠름 |
| no_tool | 12 | 2.24 | 2.86 | ✅ 매우 빠름 |
| weather | 25 | 5.06 | 7.26 | ✅ 빠름 |
| web | 24 | 12.49 | 28.59 | ⚠️ 느림 |
| case2 | 40 | 15.13 | 29.56 | ⚠️ 느림 |
| case2_review | 20 | 18.49 | 34.76 | ⚠️ 느림 |
| weather_places | 50 | 20.14 | 37.88 | ❌ 매우 느림 |
| case3_fallback | 20 | 31.89 | 37.02 | ❌ 매우 느림 |

### 응답 시간 분석

**✅ 빠른 케이스 (< 10초)**
- **map (1.35s)**: 지도 검색은 단순 API 호출만 필요
- **no_tool (2.24s)**: Tool 호출 없이 바로 응답
- **weather (5.06s)**: 날씨 API 단일 호출

**⚠️ 느린 케이스 (10-20초)**
- **web (12.49s)**: 웹 검색 API 대기 시간
- **case2 (15.13s)**: RAG 검색 + 임베딩 계산
- **case2_review (18.49s)**: RAG 검색 + 리뷰 분석

**❌ 매우 느린 케이스 (> 20초)**
- **weather_places (20.14s)**: 날씨 + 시설 검색 (순차 호출)
- **case3_fallback (31.89s)**: RAG 실패 → 웹 검색 전환 (이중 시도)


---

## 종합 평가 및 개선 로드맵

### 📊 현재 상태 요약

| 영역 | 점수/성능 | 등급 |
|------|-----------|------|
| 답변 품질 (종합) | 3.75 / 5.0 | 🟡 보통 |
| Tool 선택 정확도 | 67.6% | 🟡 보통 |
| 단일 케이스 성공률 | 95-100% | 🟢 우수 |
| 복합 케이스 성공률 | 5-50% | 🔴 매우 낮음 |
| RAG F1-Score | 0.578 | 🟡 보통 |
| 평균 응답 시간 | 14.69s | 🟡 보통 |
| 시스템 안정성 | 100% | 🟢 완벽 |


### 🎯 우선순위별 개선 과제

#### **Priority 1 (긴급) - 기능 정확성**

**1. no_tool 판단 로직 개선** ❌ 8.3% → 🎯 90%+
- **현상**: Tool이 필요 없는데도 91.7%가 잘못 호출
- **예시**:
  - 질문: "안녕?" → 기대: 바로 답변, 실제: Tool 호출 시도
  - 질문: "고마워" → 기대: 바로 답변, 실제: Tool 호출 시도
- **원인**: AI가 Tool 호출 여부를 판단하는 로직 부재
- **해결**:
  - 프롬프트에 "도구가 필요한 경우만 사용" 명시 강화
  - 질문 유형 분류기 추가 (일반 대화 vs 기능 요청)
  - Few-shot 예시 추가 (Tool 불필요한 케이스)

**2. case3_fallback 메커니즘 재설계** ❌ 5.0% → 🎯 80%+
- **현상**: RAG 결과 없을 때 웹 검색으로 전환 실패 (95% 실패)
- **예시**: "희귀한 프로그램 찾아줘" → RAG 0건 → 웹 검색 호출해야 함
- **원인**: Fallback 트리거 조건이 명확하지 않음
- **해결**:
  - RAG 결과 신뢰도 점수 도입
  - 임계값 이하 시 자동으로 웹 검색 호출
  - Fallback 로직 명시적 구현


#### **Priority 2 (중요) - 복합 케이스 성능**

**3. weather_places 순차 호출 개선** ⚠️ 50.0% → 🎯 85%+
- **현상**: 날씨와 시설 검색을 모두 호출해야 하는데 하나만 호출
- **예시**: "내일 날씨 좋으면 공원 추천해줘"
  - 기대: get_weather_forecast → search_facilities
  - 실제: 날씨만 확인 또는 공원만 검색
- **원인**: 복합 의도 파악 부족, Tool 체이닝 로직 미흡
- **해결**:
  - 다단계 Task 계획 수립 (Plan → Execute)
  - "날씨 확인 → 결과 기반으로 장소 추천" 템플릿 추가
  - Chain-of-Thought 프롬프팅

**4. Tool 선택 정확도 향상** 🟡 67.6% → 🎯 85%+
- **해결**:
  - Few-shot 예시 강화 (각 Tool 사용 시나리오)
  - Tool 설명 개선 (언제 사용해야 하는지 명확히)
  - 질문 의도 파악 개선


#### **Priority 3 (개선) - 검색 품질**

**5. RAG 검색 정확도 개선** ⚠️ F1: 0.578 → 🎯 0.80+
- **해결**:
  - 하이브리드 검색 도입 (벡터 + BM25)
  - 임베딩 모델 업그레이드 (multilingual-e5 → OpenAI ada-002)
  - 쿼리 확장 (Query expansion)
  - 리랭킹 모델 추가

**6. 답변 정확성 향상** 🟡 3.48 → 🎯 4.2+
- **해결**:
  - 검색 품질 개선 (위 5번과 연계)
  - 사실 검증 레이어 추가
  - 환각 방지 프롬프트 강화
  - Ground truth 명시적 참조


#### **Priority 4 (최적화) - 성능 개선**

**7. 응답 속도 최적화** ⚠️ 14.69s → 🎯 <10s
- **해결**:
  - RAG 검색 결과 캐싱 (동일/유사 질문)
  - 병렬 Tool 호출 (독립적인 Tool은 동시 실행)
  - 임베딩 배치 처리
  - 프롬프트 토큰 수 최적화

**8. case3_fallback 응답 시간 단축** ❌ 31.89s → 🎯 <20s
- **해결**:
  - 조기 종료 조건 설정 (RAG 신뢰도 임계값)
  - 타임아웃 설정 (무한 대기 방지)
  - 병렬 검색 (RAG + Web을 동시에 시도)


### 📈 기대 효과 (개선 완료 시)

| 지표 | 현재 | 목표 | 개선률 |
|------|------|------|--------|
| Tool 선택 정확도 | 67.6% | 85%+ | +26% |
| 복합 케이스 성공률 | 5-50% | 80%+ | +400-1500% |
| RAG F1-Score | 0.578 | 0.80+ | +38% |
| 평균 응답 시간 | 14.69s | <10s | -32% |
| 답변 정확성 | 3.48 | 4.2+ | +21% |


### 🔍 모니터링 지표

개선 후 지속적으로 추적해야 할 KPI:
- Tool 선택 정확도 > 85%
- no_tool 판단 정확도 > 90%
- 복합 케이스 성공률 > 80%
- 평균 응답 시간 < 10초
- RAG F1-Score > 0.80
- 사용자 만족도 (답변 품질) > 4.0/5.0


---

**보고서 생성 일시**: 2025-11-25
**버전**: v3.0 (파라미터 정확도 제거, 서비스 품질 강화)
