"""
RAG ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- Precision@K
- Recall@K
- MRR (Mean Reciprocal Rank)
"""

import json
import sys
import os
import argparse
import random
from pathlib import Path
import re

# ë°±ì—”ë“œ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "backend"))

from typing import List, Dict, Any
import numpy as np
import chromadb
from chromadb.config import Settings as ChromaSettings
from langchain.schema import Document

# ë°±ì—”ë“œ ì„¤ì •/ì„ë² ë”©ì„ ì¬ì‚¬ìš©í•˜ì—¬ retrieverë¥¼ ì§ì ‘ êµ¬ì„± (backend ì½”ë“œëŠ” ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
try:
    from config import settings
    from models.pca_embeddings import pca_embeddings
except Exception:
    settings = None
    pca_embeddings = None


def _build_retriever():
    """ChromaDB + pca_embeddingsë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ retriever êµ¬ì„±"""
    if not settings or not pca_embeddings:
        print("âŒ retriever êµ¬ì„± ì‹¤íŒ¨: settings ë˜ëŠ” pca_embeddings ë¡œë“œ ë¶ˆê°€")
        return None

    try:
        client = chromadb.HttpClient(
            host=settings.CHROMA_HOST,
            port=settings.CHROMA_PORT,
            settings=ChromaSettings(anonymized_telemetry=False),
        )
        collection = client.get_collection(name="kid_program_collection")
    except Exception as e:
        print(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

    class SimpleRetriever:
        def get_relevant_documents(self, query: str, n_results: int = 50):
            embedding = pca_embeddings.embed_query(query)
            results = collection.query(
                query_embeddings=[embedding],
                n_results=n_results,
                include=["metadatas", "documents"],
            )
            docs = []
            ids = results.get("ids", [[]])[0] if results.get("ids") else []
            metadatas = results.get("metadatas", [[]])[0] if results.get("metadatas") else []
            documents = results.get("documents", [[]])[0] if results.get("documents") else []
            for i, doc_id in enumerate(ids):
                metadata = metadatas[i] if i < len(metadatas) else {}
                metadata = dict(metadata or {})
                metadata["id"] = doc_id
                text = documents[i] if i < len(documents) else ""
                docs.append(Document(page_content=text, metadata=metadata))
            return docs

    return SimpleRetriever()


def precision_at_k(retrieved: List[str], relevant: List[str], k: int) -> float:
    """ê²€ìƒ‰ëœ Kê°œ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨"""
    if not retrieved or not relevant:
        return 0.0

    # ì •ê·œí™” í›„ ì •í™•íˆ ì¼ì¹˜í•  ë•Œë§Œ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ìœ¼ë¡œ ì˜ëª» ì¹´ìš´íŠ¸ë˜ëŠ” ê²½ìš° ë°©ì§€)
    def norm(s: str) -> str:
        return re.sub(r"[\s\W]+", "", str(s).lower())

    def is_match(a: str, b: str) -> bool:
        return norm(a) == norm(b)

    relevant_norm = [norm(x) for x in relevant]
    hits = 0
    for doc in retrieved[:k]:
        d = norm(doc)
        if any(is_match(d, r) for r in relevant_norm):
            hits += 1
    return hits / k


def recall_at_k(retrieved: List[str], relevant: List[str], k: int) -> float:
    """ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ì¤‘ ê²€ìƒ‰ëœ ë¹„ìœ¨"""
    if not relevant:
        return 0.0

    def norm(s: str) -> str:
        return re.sub(r"[\s\W]+", "", str(s).lower())

    def is_match(a: str, b: str) -> bool:
        return norm(a) == norm(b)

    relevant_norm = [norm(x) for x in relevant]
    matched = set()

    for doc in retrieved[:k]:
        d = norm(doc)
        for idx, r in enumerate(relevant_norm):
            if idx in matched:
                continue
            if is_match(d, r):
                matched.add(idx)
                break

    return len(matched) / len(relevant_norm) if relevant_norm else 0.0


def mean_reciprocal_rank(retrieved: List[str], relevant: List[str]) -> float:
    """ì²« ì •ë‹µ ìˆœìœ„ì˜ ì—­ìˆ˜"""
    if not retrieved or not relevant:
        return 0.0

    def norm(s: str) -> str:
        return re.sub(r"[\s\W]+", "", str(s).lower())

    def is_match(a: str, b: str) -> bool:
        return norm(a) == norm(b)

    relevant_norm = [norm(x) for x in relevant]
    for i, doc in enumerate(retrieved, 1):
        d = norm(doc)
        if any(is_match(d, r) for r in relevant_norm):
            return 1.0 / i
    return 0.0


def evaluate_rag_quality(
    retriever,
    test_data: List[Dict[str, Any]],
    k_precision: int = 3,
    k_recall: int = 20,
    n_results: int = 50
) -> Dict[str, Any]:
    """RAG ê²€ìƒ‰ í’ˆì§ˆ ì „ì²´ í‰ê°€"""

    precisions = []
    recalls = []
    mrrs = []

    results = []

    for item in test_data:
        question = item["question"]
        relevant_docs = item.get("relevant_doc_ids", [])

        # ê´€ë ¨ ë¬¸ì„œ IDê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not relevant_docs:
            continue

        # ê²€ìƒ‰ ìˆ˜í–‰
        try:
            retrieved_docs = retriever.get_relevant_documents(question, n_results=n_results)

            # Nameì„ ìš°ì„  ì‹ë³„ìë¡œ ì‚¬ìš©í•˜ê³ , ì—†ì„ ê²½ìš° id/ìˆœë²ˆ ì‚¬ìš©
            retrieved_ids = []
            for i, doc in enumerate(retrieved_docs):
                md = doc.metadata or {}
                name_candidate = md.get("Name") or md.get("name")
                id_candidate = md.get("id") or md.get("Id") or md.get("ID")
                identifier = name_candidate or id_candidate or str(i)
                retrieved_ids.append(str(identifier))
        except Exception as e:
            print(f"Error retrieving for question '{question}': {e}")
            continue

        # ë©”íŠ¸ë¦­ ê³„ì‚° (ëŒ€ì†Œë¬¸ì/ê³µë°± ë¬´ì‹œ)
        norm_retrieved = [str(x).strip().lower() for x in retrieved_ids]
        norm_relevant = [str(x).strip().lower() for x in relevant_docs]

        p_at_k = precision_at_k(norm_retrieved, norm_relevant, k_precision)
        r_at_k = recall_at_k(norm_retrieved, norm_relevant, k_recall)
        mrr = mean_reciprocal_rank(norm_retrieved, norm_relevant[:k_precision])

        precisions.append(p_at_k)
        recalls.append(r_at_k)
        mrrs.append(mrr)

        results.append({
            "question": question,
            "retrieved": retrieved_ids[:k_recall],
            "relevant": relevant_docs,
            "precision_at_k": p_at_k,
            "recall_at_k": r_at_k,
            "mrr": mrr
        })

    if not precisions:
        return {
            "error": "No questions with relevant_doc_ids found",
            "note": "RAG í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” test_questions_updated.jsonì˜ relevant_doc_idsë¥¼ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤."
        }

    return {
        "summary": {
            "total_evaluated": len(precisions),
            "precision_at_k": {
                "mean": float(np.mean(precisions)),
                "std": float(np.std(precisions)),
                "min": float(np.min(precisions)),
                "max": float(np.max(precisions))
            },
            "recall_at_k": {
                "mean": float(np.mean(recalls)),
                "std": float(np.std(recalls)),
                "min": float(np.min(recalls)),
                "max": float(np.max(recalls))
            },
            "mrr": {
                "mean": float(np.mean(mrrs)),
                "std": float(np.std(mrrs)),
                "min": float(np.min(mrrs)),
                "max": float(np.max(mrrs))
            },
            "k_precision": k_precision,
            "k_recall": k_recall
        },
        "details": results
    }


def main():
    """RAG í‰ê°€ ì‹¤í–‰"""
    parser = argparse.ArgumentParser(description="RAG ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€")
    parser.add_argument("--sample", "-s", type=int, help="í‰ê°€í•  ìƒ˜í”Œ ê°œìˆ˜ (relevant_doc_idsê°€ ìˆëŠ” ì§ˆë¬¸ ì¤‘ ëœë¤)")
    parser.add_argument("--k-precision", type=int, default=3, help="Precision@Kì— ì‚¬ìš©í•  K (default: 3)")
    parser.add_argument("--k-recall", type=int, default=20, help="Recall@Kì— ì‚¬ìš©í•  K (default: 20)")
    parser.add_argument("--n-results", type=int, default=50, help="retrieverì—ì„œ ê°€ì ¸ì˜¬ ê²°ê³¼ ìˆ˜ (default: 50)")
    args = parser.parse_args()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    dataset_path = Path(__file__).parent.parent / "datasets" / "test_questions_prompt_pruned.json"

    with open(dataset_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    test_questions = data["questions"]

    # RAG ê´€ë ¨ ë¬¸ì„œê°€ ì„¤ì •ëœ ì§ˆë¬¸ë§Œ í•„í„°ë§
    rag_questions = [q for q in test_questions if q.get("relevant_doc_ids")]

    # ìƒ˜í”Œë§
    if args.sample and len(rag_questions) > args.sample:
        rag_questions = random.sample(rag_questions, args.sample)
        print(f"ğŸ“Š ìƒ˜í”Œ í‰ê°€: {len(rag_questions)}ê°œ ì§ˆë¬¸ ì‚¬ìš©")

    if not rag_questions:
        print("âš ï¸ RAG í‰ê°€ë¥¼ ìœ„í•œ relevant_doc_idsê°€ ì„¤ì •ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("test_questions_prompt_pruned.jsonì˜ relevant_doc_idsë¥¼ ë¨¼ì € ì±„ì›Œì£¼ì„¸ìš”.")
        return {
            "error": "No RAG test data available",
            "note": "relevant_doc_ids í•„ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”"
        }

    # í‰ê°€ì—ì„œ ì§ì ‘ retrieverë¥¼ êµ¬ì„± (backend ì½”ë“œ ìˆ˜ì • ì—†ìŒ)
    retriever = _build_retriever()
    if retriever is None:
        return {
            "error": "Retriever unavailable",
            "note": "settings/pca_embeddings ë¡œë“œ ë˜ëŠ” Chroma ì—°ê²° ì‹¤íŒ¨"
        }

    results = evaluate_rag_quality(
        retriever,
        rag_questions,
        k_precision=args.k_precision,
        k_recall=args.k_recall,
        n_results=args.n_results
    )

    # ê²°ê³¼ ì €ì¥
    output_path = Path(__file__).parent.parent / "results" / "rag_evaluation.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"âœ… RAG í‰ê°€ ì™„ë£Œ: {output_path}")
    return results


if __name__ == "__main__":
    results = main()
    if "summary" in results:
        print("\n=== RAG í‰ê°€ ìš”ì•½ ===")
        summary = results["summary"]
        print(f"í‰ê°€ ì§ˆë¬¸ ìˆ˜: {summary['total_evaluated']}")
        print(f"Precision@{summary['k_precision']}: {summary['precision_at_k']['mean']:.3f} (Â±{summary['precision_at_k']['std']:.3f})")
        print(f"Recall@{summary['k_recall']}: {summary['recall_at_k']['mean']:.3f} (Â±{summary['recall_at_k']['std']:.3f})")
        print(f"MRR: {summary['mrr']['mean']:.3f} (Â±{summary['mrr']['std']:.3f})")
